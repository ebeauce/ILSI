{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "varying-traffic",
   "metadata": {},
   "source": [
    "# Stress inversion on synthetic data sets\n",
    "\n",
    "You may have to install `pyrocko` [https://pyrocko.org/](https://pyrocko.org/), and `mplstereonet` [https://github.com/joferkington/mplstereonet](https://github.com/joferkington/mplstereonet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "import sys\n",
    "\n",
    "# import the iterative linear stress inversion package\n",
    "import ILSI\n",
    "\n",
    "import synthetic_dataset as data\n",
    "from experiment_parameters import *\n",
    "\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time as give_time\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.colorbar as clb\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import mplstereonet\n",
    "\n",
    "from pyrocko import moment_tensor as pmt\n",
    "\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "\n",
    "# set plotting parameters\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.3)\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette('colorblind')\n",
    "plt.rcParams['savefig.dpi'] = 200\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "# define the color palette\n",
    "_colors_ = ['C0', 'C2', 'C1', 'C4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-privilege",
   "metadata": {},
   "source": [
    "## Design the stress tensor, which we will try to retrieve by inverting the (noisy) focal mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_x3(theta):\n",
    "    theta = theta*np.pi/180.\n",
    "    R3 = np.array([[np.cos(theta), -np.sin(theta), 0.],\n",
    "                   [np.sin(theta), np.cos(theta), 0.],\n",
    "                   [0., 0., 1.]])\n",
    "    return R3\n",
    "\n",
    "def rotation_x1(theta):\n",
    "    theta = theta*np.pi/180.\n",
    "    R1 = np.array([[1., 0., 0.],\n",
    "                   [0., np.cos(theta), -np.sin(theta)],\n",
    "                   [0., np.sin(theta), np.cos(theta)]])\n",
    "    return R1\n",
    "\n",
    "def design_stress_tensor(exp_number, angle=45., R=None):\n",
    "    # design stress tensor\n",
    "    # stress tensor in the (north, west, upward) coordinate system\n",
    "    # we define a base stress tensor promoting right-lateral\n",
    "    # strike-slip faulting on E-W faults\n",
    "    # rotations of this base stress tensor create new stress regimes\n",
    "    # where the dominant faulting regime is normal, reverse, and a combination\n",
    "    # of all the above\n",
    "    sig1 = np.array([-1./np.sqrt(2.), -1./np.sqrt(2.), 0.])\n",
    "    sig2 = np.array([0., 0., +1.])\n",
    "    sig3 = np.array([-1./np.sqrt(2.), 1./np.sqrt(2.), 0.])\n",
    "    basis = np.stack((sig1, sig2, sig3), axis=1)\n",
    "    if R is None:\n",
    "        R = 0.50\n",
    "    if exp_number == 1:\n",
    "        # SS\n",
    "        V = basis\n",
    "    elif exp_number == 2:\n",
    "        # SS-R\n",
    "        # rotate the eigenvectors by *angle* degrees about the sig1-axis\n",
    "        # first, do the rotation in the eigenbasis\n",
    "        new_eig = rotation_x1(45.).dot(np.identity(3))\n",
    "        # next, go back to the (north, west, up) basis\n",
    "        V = basis.dot(new_eig)\n",
    "    elif exp_number == 3:\n",
    "        # R\n",
    "        V = basis.dot(rotation_x1(90.))\n",
    "    elif exp_number == 4:\n",
    "        # SS-N\n",
    "        V = basis.dot(rotation_x3(45.))\n",
    "    elif exp_number == 5:\n",
    "        # N\n",
    "        V = basis.dot(rotation_x3(90.))\n",
    "    # tension positive\n",
    "    s1, s2, s3 = -1., 2*R-1., +1.\n",
    "    S = np.diag(np.array([s1, s2, s3]) - np.sum([s1, s2, s3])/3.)\n",
    "    S /= np.sqrt(np.sum(S**2))\n",
    "    stress_tensor = np.dot(V, np.dot(S, V.T))\n",
    "    return stress_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de485ca-0fd5-42aa-97ea-8fcea8659d3a",
   "metadata": {},
   "source": [
    "Choose `st_nb` between 1 and 5. It defines the directions of the principal stresses (see Beauce et al. 2021, Table 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_nb = 1\n",
    "stress_tensor = design_stress_tensor(st_nb, R=0.50)\n",
    "true_stress_tensor = stress_tensor # alias\n",
    "# fix the number of data\n",
    "n_earthquakes = 250\n",
    "# plot azimuth/plunge of principal stresses\n",
    "p_sig, p_dir = ILSI.utils_stress.stress_tensor_eigendecomposition(stress_tensor)\n",
    "for i in range(3):\n",
    "    print(f'Azimuth and plunge of principal direction {i+1}: ', ILSI.utils_stress.get_bearing_plunge(p_dir[:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-titanium",
   "metadata": {},
   "source": [
    "## Fault planes verifying the Mohr-Coulomb failure criterion (Vavrycuk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3650-1faf-4a78-be5a-4c620f8ed52f",
   "metadata": {},
   "source": [
    "Choose `exp_label` between 1 and 6. It defines the data scenario as defined in Beauce et al. 2021, Table 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_label = 1 # the average friction is different from the assumed friction in the computation of I\n",
    "# all experiment parameters are defined in experiment_parameters.py\n",
    "mu = exp_params[exp_label]['mu']\n",
    "min_instability = exp_params[exp_label]['min_instability']\n",
    "# if the resolved shear stress on the randomly generated fault plane is below the Mohr-Coulomb failure criterion,\n",
    "# the fault plane is kept with probability no higher than max_acceptance_p, and decreasing probability\n",
    "# according to I\n",
    "max_acceptance_p = exp_params[exp_label]['max_acceptance_p']\n",
    "random_comp_friction = exp_params[exp_label]['random_comp_friction']\n",
    "strikes, dips, fig_Mohr = data.random_data_failure(\n",
    "    n_earthquakes, stress_tensor, mu, min_instability,\n",
    "    max_acceptance_probability=max_acceptance_p,\n",
    "    random_friction=random_comp_friction,\n",
    "    naive_uniform=False)\n",
    "#fig_Mohr.savefig(fig_Mohr._label + '.svg', format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-intent",
   "metadata": {},
   "source": [
    "## Compute slip vectors according to the Wallace-Bott assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, compute the fault normals\n",
    "n, _ = ILSI.utils_stress.normal_slip_vectors(strikes, dips, np.zeros_like(strikes))\n",
    "traction, normal_traction, shear_traction = \\\n",
    "        ILSI.utils_stress.compute_traction(true_stress_tensor, n.T)\n",
    "shear_dir = shear_traction/np.sqrt(np.sum(shear_traction**2, axis=-1, keepdims=True))\n",
    "# find the rake that will make slip in the same direction as shear\n",
    "s, d, rakes = np.asarray(list(map(ILSI.utils_stress.strike_dip_rake, n.T, shear_dir))).T\n",
    "print(np.allclose(s, strikes, atol=1.e-3), np.allclose(d, dips, atol=1.e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot P/T axes\n",
    "fig_PT = data.plot_dataset_PT(\n",
    "    strikes, dips, rakes, stress_tensor=stress_tensor, figname='')\n",
    "# add the principal faults\n",
    "n1, n2 = ILSI.utils_stress.principal_faults(stress_tensor, mu)\n",
    "s1, d1, _ = ILSI.utils_stress.strike_dip_rake(n1, np.zeros(3))\n",
    "s2, d2, _ = ILSI.utils_stress.strike_dip_rake(n2, np.zeros(3))\n",
    "print(s1, d1)\n",
    "print(s2, d2)\n",
    "ax = fig_PT.get_axes()[1]\n",
    "ax.plane(s1, d1, lw=1.0, color='k')\n",
    "ax.plane(s2, d2, lw=1.0, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4c3bb-8160-48ed-8ba9-7768a3ca36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://josealvarezgomez.wordpress.com/2014/04/22/fmc-a-python-program-to-manage-classify-and-plot-focal-mechanism-data/ to build the Kaverina diagram.\n",
    "# # plot data in Kaverina diagram\n",
    "# sys.path.append(os.path.join('/home/eric/Dropbox (MIT)/DANA/temporary_working_dir/focal_mechanisms/FMC/'))\n",
    "# import plotFMC\n",
    "# import functionsFMC\n",
    "# from functionsFMC import kave, mecclass\n",
    "\n",
    "# # determine the t and p axes\n",
    "# P_axis = np.zeros((n_earthquakes, 2), dtype=np.float32)\n",
    "# T_axis = np.zeros((n_earthquakes, 2), dtype=np.float32)\n",
    "# B_axis = np.zeros((n_earthquakes, 2), dtype=np.float32)\n",
    "# faulting_type = np.zeros(n_earthquakes, dtype=np.int32)\n",
    "# fm_type = []\n",
    "# r2d = 180./np.pi\n",
    "# for t in range(n_earthquakes):\n",
    "#     # first, get normal and slip vectors from\n",
    "#     # strike, dip, rake\n",
    "#     normal, slip = ILSI.utils_stress.normal_slip_vectors(strikes[t], dips[t], rakes[t])\n",
    "#     # second, get the t and p vectors\n",
    "#     p_axis, t_axis, b_axis =\\\n",
    "#             ILSI.utils_stress.p_t_b_axes(normal, slip)\n",
    "#     p_bearing, p_plunge = ILSI.utils_stress.get_bearing_plunge(p_axis)\n",
    "#     t_bearing, t_plunge = ILSI.utils_stress.get_bearing_plunge(t_axis)\n",
    "#     b_bearing, b_plunge = ILSI.utils_stress.get_bearing_plunge(b_axis)\n",
    "#     P_axis[t, :] = p_bearing, p_plunge\n",
    "#     T_axis[t, :] = t_bearing, t_plunge\n",
    "#     B_axis[t, :] = b_bearing, b_plunge\n",
    "#     fm_type.append(mecclass(t_plunge, b_plunge, p_plunge))\n",
    "# # get the x, y coordinates for FMC's plots\n",
    "# x_kave, y_kave = kave(T_axis[:, 1], B_axis[:, 1], P_axis[:, 1])\n",
    "\n",
    "# colors_fm = {}\n",
    "# colors_fm['SS'] = 'C0'\n",
    "# colors_fm['SS-N'] = 'C0'\n",
    "# colors_fm['SS-R'] = 'C0'\n",
    "# colors_fm['R'] = 'C1'\n",
    "# colors_fm['R-SS'] = 'C1'\n",
    "# colors_fm['N'] = 'C2'\n",
    "# colors_fm['N-SS'] = 'C2'\n",
    "# colors = np.asarray([colors_fm[fm] for fm in fm_type])\n",
    "\n",
    "\n",
    "# fig_Kav = plt.figure('Kaverina_diagram', figsize=(12, 12))\n",
    "# ax = fig_Kav.add_subplot(111)\n",
    "# fig_Kav = plotFMC.baseplot(10, '', ax=ax)\n",
    "# ax.scatter(x_kave, y_kave, color=colors, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626164f-0634-4bfc-905e-f8eb98be2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot principal focal mechanisms\n",
    "# 1) get the fault normals\n",
    "n1, n2 = ILSI.utils_stress.principal_faults(stress_tensor, mu)\n",
    "# 2) get the direction maximum shear on these planes\n",
    "T1, Tn1, Ts1 = ILSI.utils_stress.compute_traction(stress_tensor, n1.T)\n",
    "T2, Tn2, Ts2 = ILSI.utils_stress.compute_traction(stress_tensor, n2.T)\n",
    "# 3) take the slip vector as the unitary vector along the maximum shear\n",
    "s1 = Ts1/np.linalg.norm(Ts1, 2)\n",
    "s2 = Ts2/np.linalg.norm(Ts2, 2)\n",
    "# 4) convert the normal and slip vectors to strike/dip/rake\n",
    "strike1, dip1, rake1 = ILSI.utils_stress.strike_dip_rake(n1.squeeze(), s1.squeeze())\n",
    "strike2, dip2, rake2 = ILSI.utils_stress.strike_dip_rake(n2.squeeze(), s2.squeeze())\n",
    "# plot\n",
    "from obspy.imaging.beachball import beach\n",
    "bb1 = beach([strike1, dip1, rake1], facecolor='C0', xy=(0., 0.), width=1.)\n",
    "bb2 = beach([strike2, dip2, rake2], facecolor='C0', xy=(1.3, 0.), width=1.)\n",
    "print(strike1, dip1, rake1)\n",
    "print(strike2, dip2, rake2, n2[2, 0])\n",
    "fig, ax = plt.subplots(num='principal_focal_mechanisms', figsize=(12, 5))\n",
    "ax.add_collection(bb1)\n",
    "ax.add_collection(bb2)\n",
    "ax.text(-0.4, 0.6, 'Principal focal mechanism 1')\n",
    "ax.text(0.9, 0.6, 'Principal focal mechanism 2')\n",
    "ax.axis('off')\n",
    "ax.autoscale_view(tight=False)\n",
    "ax.set_aspect('equal')\n",
    "fig.savefig(f'{fig._label}_st{st_nb}' + '.png', format='png', bbox_inches='tight')\n",
    "fig.savefig(f'{fig._label}_st{st_nb}' + '.svg', format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-harassment",
   "metadata": {},
   "source": [
    "## Compute the (normalized) moment tensors from the strikes/dips/rakes\n",
    "\n",
    "The addition of noise will be conducted directly on the moment tensors, by rotated them about a randomly chosen axis, and a randomly chosen rotation angle (but with controlled max value, larger max angle means more noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt0 = []\n",
    "for i in range(n_earthquakes):\n",
    "    mt0_ = pmt.as_mt([strikes[i], dips[i], rakes[i]])\n",
    "    # normalize it so that we don't deal with tiny numerical values\n",
    "    mt0_ = pmt.as_mt(mt0_.m()/np.sqrt(np.sum(mt0_.m()**2)))\n",
    "    mt0.append(mt0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-conservative",
   "metadata": {},
   "source": [
    "## Loop through many levels of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigendecomposition of the true stress tensor\n",
    "true_p_sig, true_p_dir = ILSI.utils_stress.stress_tensor_eigendecomposition(\n",
    "            true_stress_tensor)\n",
    "true_R = ILSI.utils_stress.R_(true_p_sig)\n",
    "# true shear stresses (directions and magnitudes)\n",
    "true_n, _ = ILSI.utils_stress.normal_slip_vectors(strikes, dips, np.zeros_like(strikes))\n",
    "true_traction, true_normal_traction, true_shear_traction = \\\n",
    "        ILSI.utils_stress.compute_traction(true_stress_tensor, true_n.T)\n",
    "true_shear_mag = np.sqrt(np.sum(shear_traction**2, axis=-1))\n",
    "true_shear_dir = true_shear_traction/true_shear_mag[..., np.newaxis]\n",
    "# true strikes, dips, rakes\n",
    "true_strikes = strikes.copy()\n",
    "true_dips = dips.copy()\n",
    "true_rakes = rakes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the functions to quantify error of the inverted solutions\n",
    "def inner_prod(x, y):\n",
    "    # need to clip the inner product, or numerical imprecisions can produce\n",
    "    # values slightly larger than +1 or slightly smaller than -1, which\n",
    "    # gives NaN in arccos\n",
    "    return np.clip(np.sum(x*y, axis=-1), -1, +1)\n",
    "\n",
    "def mean_stress_angle(true_p_directions, inv_p_directions):\n",
    "    angles = np.zeros(3, dtype=np.float32)\n",
    "    for i in range(3):\n",
    "        # switch the direction of one vector and look for the smallest angle\n",
    "        cos_i = np.array([inner_prod(true_p_directions[:, i], inv_p_directions[:, i]),\n",
    "                          inner_prod(-true_p_directions[:, i], inv_p_directions[:, i])])\n",
    "        angles[i] = np.min(np.abs(np.arccos(cos_i)))\n",
    "    mean_angle = np.mean(np.abs(angles))\n",
    "    return mean_angle*180./np.pi\n",
    "\n",
    "def shape_ratio_error(true_R, inv_R):\n",
    "    return abs(true_R - inv_R)\n",
    "    #return abs(true_R - inv_R)/true_R\n",
    "\n",
    "def shear_error(true_shear_dir, true_shear_mag, inv_stress_tensor):\n",
    "    traction, normal_traction, shear_traction = \\\n",
    "            ILSI.utils_stress.compute_traction(inv_stress_tensor, true_n.T)\n",
    "    inv_shear_mag = np.sqrt(np.sum(shear_traction**2, axis=-1))\n",
    "    inv_shear_dir = shear_traction/inv_shear_mag[..., np.newaxis]\n",
    "    mag_error = np.mean(np.abs(true_shear_mag - inv_shear_mag)/true_shear_mag)\n",
    "\n",
    "    dir_error = np.mean(np.abs(np.arccos(inner_prod(true_shear_dir, inv_shear_dir))))\n",
    "    return mag_error, dir_error*180./np.pi\n",
    "\n",
    "def perturb_moment_tensors(mt0, max_rotation_angle):\n",
    "    strikes_n, dips_n, rakes_n = np.zeros((3, len(mt0)), dtype=np.float32)\n",
    "    for i in range(len(mt0)):\n",
    "        # generate random rotation matrix\n",
    "        R_random = ILSI.utils_stress.random_rotation(\n",
    "            max_angle=max_rotation_angle)\n",
    "        # rotate the moment tensor\n",
    "        mt_noisy = pmt.as_mt(R_random.dot(mt0[i].m().dot(R_random.T)))\n",
    "        strikes_n[i], dips_n[i], rakes_n[i] = \\\n",
    "            mt_noisy.strike1, mt_noisy.dip1, mt_noisy.rake1\n",
    "    return strikes_n, dips_n, rakes_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversion parameters\n",
    "friction_min = 0.1\n",
    "friction_max = 1.1\n",
    "friction_step = 0.05\n",
    "n_random_selections = 20\n",
    "n_stress_iter = 10\n",
    "n_averaging_ILSI = 1\n",
    "n_exp_per_noise = 30\n",
    "#n_resamplings = 1000\n",
    "ILSI_kwargs = {}\n",
    "ILSI_kwargs['max_n_iterations'] = 300\n",
    "ILSI_kwargs['shear_update_atol'] = 1.e-5\n",
    "Tarantola_kwargs0 = {}\n",
    "inversion_output = {}\n",
    "methods = ['constant_shear', 'variable_shear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define routine to run sub-experiment to easily distribute\n",
    "# several sub-experiments accross multiple cores\n",
    "# the following function should be adequate for multi-threading:\n",
    "def run_subexperiment(dataset_size, max_rotation_angle, n_exp_per_noise):\n",
    "    #print(f'Size of the data set: {dataset_size}')\n",
    "    averaged_results = {}\n",
    "    # repeat the experiment several times for a given noise level\n",
    "    # and dataset size to mitigate the effect of pathological datasets\n",
    "    subexp_output = {}\n",
    "    for method in methods:\n",
    "        averaged_results[method] = {}\n",
    "        subexp_output[method] = {}\n",
    "        for item in ['stress_dir', 'shape_ratio', 'shear_mag',\n",
    "                     'shear_dir', 'friction']:\n",
    "            subexp_output[method][item] = np.zeros(n_exp_per_noise, dtype=np.float32)\n",
    "        subexp_output[method]['stress_tensor'] = np.zeros((n_exp_per_noise, 3, 3), dtype=np.float32)\n",
    "    for i_noise in range(n_exp_per_noise):\n",
    "        subset = np.random.choice(\n",
    "            np.arange(len(true_strikes)), dataset_size, replace=False)\n",
    "        mt0_subset = [mt0[i_sub] for i_sub in subset]\n",
    "        strikes_1n, dips_1n, rakes_1n = perturb_moment_tensors(\n",
    "            mt0_subset, max_rotation_angle=max_rotation_angle)\n",
    "        # invert\n",
    "        for method in methods:\n",
    "            if method == 'constant_shear':\n",
    "                variable_shear = False\n",
    "            else:\n",
    "                variable_shear = True\n",
    "            subexp_output[method]['stress_tensor'][i_noise, ...],\\\n",
    "            subexp_output[method]['friction'][i_noise], p_stresses, p_dir =\\\n",
    "                    ILSI.ilsi.inversion_one_set_instability(\n",
    "                            strikes_1n, dips_1n, rakes_1n,\n",
    "                            n_random_selections=n_random_selections,\n",
    "                            **ILSI_kwargs,\n",
    "                            Tarantola_kwargs=Tarantola_kwargs0.copy(),\n",
    "                            friction_min=friction_min,\n",
    "                            friction_max=friction_max,\n",
    "                            friction_step=friction_step,\n",
    "                            n_stress_iter=n_stress_iter,\n",
    "                            n_averaging=n_averaging_ILSI,\n",
    "                            weighted=False,\n",
    "                            variable_shear=variable_shear, verbose=1)\n",
    "            # compute errors\n",
    "            subexp_output[method]['stress_dir'][i_noise] = ILSI.utils_stress.kagan_angle(\n",
    "                true_stress_tensor, subexp_output[method]['stress_tensor'][i_noise, ...])\n",
    "            #subexp_output[method]['stress_dir'][i_noise] = mean_stress_angle(true_p_dir, p_dir)\n",
    "            subexp_output[method]['shape_ratio'][i_noise] = shape_ratio_error(\n",
    "                true_R, ILSI.utils_stress.R_(p_stresses))\n",
    "            subexp_output[method]['shear_mag'][i_noise], subexp_output[method]['shear_dir'][i_noise]  = shear_error(\n",
    "                true_shear_dir, true_shear_mag, subexp_output[method]['stress_tensor'][i_noise, ...])\n",
    "    # average the results over the n_exp_per_noise experiments\n",
    "    for method in methods:\n",
    "        averaged_results[method]['stress_tensor'] = \\\n",
    "            np.mean(subexp_output[method]['stress_tensor'], axis=0)\n",
    "        averaged_results[method]['stress_dir'] = np.mean(subexp_output[method]['stress_dir'])\n",
    "        averaged_results[method]['shape_ratio'] = np.mean(subexp_output[method]['shape_ratio'])\n",
    "        averaged_results[method]['shear_mag'] = np.mean(subexp_output[method]['shear_mag'])\n",
    "        averaged_results[method]['shear_dir'] = np.mean(subexp_output[method]['shear_dir'])\n",
    "    return averaged_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = give_time()\n",
    "n_noise = 30\n",
    "max_rotation = np.linspace(0., 60., n_noise) # in degrees\n",
    "dataset_sizes = np.arange(50, 251, 25)\n",
    "n_datasets = len(dataset_sizes)\n",
    "errors = {}\n",
    "for method in methods:\n",
    "    errors[method] = {}\n",
    "    inversion_output[method] = {}\n",
    "    errors[method]['stress_dir'] = np.zeros((n_noise, n_datasets), dtype=np.float32)\n",
    "    errors[method]['shape_ratio'] = np.zeros((n_noise, n_datasets), dtype=np.float32)\n",
    "    errors[method]['shear_mag'] = np.zeros((n_noise, n_datasets), dtype=np.float32)\n",
    "    errors[method]['shear_dir'] = np.zeros((n_noise, n_datasets), dtype=np.float32)\n",
    "    inversion_output[method]['friction'] = np.zeros((n_noise, n_datasets), dtype=np.float32)\n",
    "    inversion_output[method]['stress_tensor'] = np.zeros((n_noise, n_datasets, 3, 3), dtype=np.float32)\n",
    "#for n1 in range(n_noise):\n",
    "for n1 in [0]:\n",
    "    print(f'------- {n1+1}/{n_noise} -------')\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        run_sub = partial(\n",
    "            run_subexperiment, max_rotation_angle=max_rotation[n1], n_exp_per_noise=n_exp_per_noise)\n",
    "        results = list(executor.map(run_sub, dataset_sizes))\n",
    "    for n2 in range(n_datasets):\n",
    "        for method in methods:\n",
    "            inversion_output[method]['stress_tensor'][n1, n2, ...] = \\\n",
    "                results[n2][method]['stress_tensor']\n",
    "            errors[method]['stress_dir'][n1, n2] = results[n2][method]['stress_dir']\n",
    "            errors[method]['shape_ratio'][n1, n2] = results[n2][method]['shape_ratio']\n",
    "            errors[method]['shear_mag'][n1, n2] = results[n2][method]['shear_mag']\n",
    "            errors[method]['shear_dir'][n1, n2] = results[n2][method]['shear_dir']          \n",
    "t_end = give_time()\n",
    "print('{:.2f}sec to run the experiment.'.format(t_end-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the errors\n",
    "def plot_errors(errors, dataset_sizes, noise_levels, figname='', title=''):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    fig, axes = plt.subplots(num=f'errors{figname}', ncols=2, nrows=2, figsize=(12, 12))\n",
    "    fig.suptitle(title)\n",
    "    cmap = 'inferno'\n",
    "    #clb_labels = ['Mean stress dir. error ('u'\\u00b0'')', 'Shape ratio error',\n",
    "    #              'Mean shear dir. error ('u'\\u00b0'')', 'Mean shear mag. error (%)']\n",
    "    clb_labels = ['Stress tensor diff. (Kagan angle,'u'\\u00b0'')', 'Shape ratio error',\n",
    "                  'Mean shear dir. error ('u'\\u00b0'')', 'Mean shear mag. error (%)']\n",
    "    keys = ['stress_dir', 'shape_ratio', 'shear_dir', 'shear_mag']\n",
    "    for ax, key, lab in zip(axes.flatten(), keys, clb_labels):\n",
    "        pcl = ax.pcolormesh(\n",
    "            dataset_sizes, noise_levels, errors[key], cmap=cmap)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='3%', pad=0.05)\n",
    "        plt.colorbar(pcl, cax=cax, label=lab)\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_xlabel('Number of Focal Mech.')\n",
    "        #ax.set_ylabel('Noise level ('u'\\u00b0'')')\n",
    "        ax.set_ylabel('Max rotation angle ('u'\\u00b0'')')\n",
    "    plt.subplots_adjust(wspace=0.25)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_errors_diff(errors, dataset_sizes, noise_levels):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    fig, axes = plt.subplots(num='errors_diff', ncols=2, nrows=2, figsize=(12, 12))\n",
    "    fig.suptitle('Difference between the constant and variable shear methods')\n",
    "    cmap = 'coolwarm'\n",
    "    #clb_labels = ['Mean stress dir. error ('u'\\u00b0'')', 'Shape ratio error',\n",
    "    #              'Mean shear dir. error ('u'\\u00b0'')', 'Mean shear mag. error (%)']\n",
    "    clb_labels = ['Stress tensor diff. (Kagan angle,'u'\\u00b0'')', 'Shape ratio error',\n",
    "                  'Mean shear dir. error ('u'\\u00b0'')', 'Mean shear mag. error (%)']\n",
    "    keys = ['stress_dir', 'shape_ratio', 'shear_dir', 'shear_mag']\n",
    "    for ax, key, lab in zip(axes.flatten(), keys, clb_labels):\n",
    "        vmax = max(abs(errors[key].max()), abs(errors[key].min()))\n",
    "        pcl = ax.pcolormesh(\n",
    "            dataset_sizes, noise_levels, errors[key], cmap=cmap, vmin=-vmax, vmax=vmax)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='3%', pad=0.05)\n",
    "        plt.colorbar(pcl, cax=cax, label=lab)\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_xlabel('Number of Focal Mech.')\n",
    "        #ax.set_ylabel('Noise level ('u'\\u00b0'')')\n",
    "        ax.set_ylabel('Max rotation angle ('u'\\u00b0'')')\n",
    "    plt.subplots_adjust(wspace=0.25)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_errors_both(errors, dataset_sizes, noise_levels):\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    figures = []\n",
    "    for method in ['constant', 'variable']:\n",
    "        figname = f'_{method}'\n",
    "        title = f'{method.capitalize()} shear stress magnitude'\n",
    "        err = errors[f'{method}_shear']\n",
    "        fig, axes = plt.subplots(num=f'errors{figname}', ncols=2, nrows=2, figsize=(12, 12))\n",
    "        fig.suptitle(title)\n",
    "        cmap = 'inferno'\n",
    "        #clb_labels = ['Mean stress dir. error ('u'\\u00b0'')', 'Shape ratio error',\n",
    "        #              'Mean shear dir. error ('u'\\u00b0'')', 'Mean shear mag. error (%)']\n",
    "        clb_labels = ['Stress tensor diff. (Kagan angle,'u'\\u00b0'')', 'Shape ratio error',\n",
    "                  'Mean shear dir. error ('u'\\u00b0'')', 'Mean shear mag. error (%)']\n",
    "        keys = ['stress_dir', 'shape_ratio', 'shear_dir', 'shear_mag']\n",
    "        for ax, key, lab in zip(axes.flatten(), keys, clb_labels):\n",
    "            vmin = 0.\n",
    "            vmax = max([errors[key2][key].max() for key2 in errors.keys()])\n",
    "            pcl = ax.pcolormesh(\n",
    "                dataset_sizes, noise_levels, err[key], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes('right', size='3%', pad=0.05)\n",
    "            plt.colorbar(pcl, cax=cax, label=lab)\n",
    "        for ax in axes.flatten():\n",
    "            ax.set_xlabel('Number of Focal Mech.')\n",
    "            #ax.set_ylabel('Noise level ('u'\\u00b0'')')\n",
    "            ax.set_ylabel('Max rotation angle ('u'\\u00b0'')')\n",
    "        plt.subplots_adjust(wspace=0.25)\n",
    "        fig.tight_layout()\n",
    "        figures.append(fig)\n",
    "    return figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one figure for each method\n",
    "#fig_cst = plot_errors(errors['constant_shear'], dataset_sizes, noise_levels,\n",
    "#                      figname='_constant', title='Constant shear stess magnitude')\n",
    "#fig_var = plot_errors(errors['variable_shear'], dataset_sizes, noise_levels,\n",
    "#                      figname='_variable', title='Variable shear stress magnitude')\n",
    "fig_cst, fig_var = plot_errors_both(errors, dataset_sizes, max_rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the difference between the two methods\n",
    "errors_diff = {}\n",
    "for key in errors['constant_shear'].keys():\n",
    "    errors_diff[key] = errors['constant_shear'][key] - errors['variable_shear'][key]\n",
    "fig_diff = plot_errors_diff(errors_diff, dataset_sizes, max_rotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-platinum",
   "metadata": {},
   "source": [
    "## Save the outputs of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the figures\n",
    "# for fig in [fig_cst, fig_var, fig_diff, fig_Mohr, fig_PT]:\n",
    "#     fig.savefig(f'{fig._label}_{exp_label}.svg', format='svg', bbox_inches='tight')\n",
    "#     fig.savefig(f'{fig._label}_{exp_label}.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the results\n",
    "# with h5.File(f'experiment_{exp_label}.h5', mode='w') as f:\n",
    "#     for method in methods:\n",
    "#         f.create_group(method)\n",
    "#         for key in errors[method].keys():\n",
    "#             f[method].create_dataset(f'err_{key}', data=errors[method][key])\n",
    "#         f[method].create_dataset('inv_stress_tensor', data=inversion_output[method]['stress_tensor'])\n",
    "#     f.create_group('metadata')\n",
    "#     f['metadata'].create_dataset('true_stress_tensor', data=true_stress_tensor)\n",
    "#     f['metadata'].create_dataset('noise_levels', data=max_rotation)\n",
    "#     f['metadata'].create_dataset('dataset_sizes', data=dataset_sizes)\n",
    "#     f.create_group('data')\n",
    "#     f['data'].create_dataset('strikes', data=strikes)\n",
    "#     f['data'].create_dataset('dips', data=dips)\n",
    "#     f['data'].create_dataset('rakes', data=rakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-pizza",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
